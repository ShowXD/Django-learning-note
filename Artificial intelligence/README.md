# 人工智慧

### 梯度下降(Gradient descent)
1. Start with random values
2. Slightly move θ0 and θ1 to reduce J(θ0, θ1)
3. Keep doing step 2 until converged


## 常見的縮寫
* Features `x`
* Target `y`
* Prediction `ŷ`
* Parameters `θ`
* Learning rate `α`

## 資料前處理
### One-hot encoding

### Label encoding

## 神經網路
`粗略簡介各神經網路的特點`
### Linear regression

### 
